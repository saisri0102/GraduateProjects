{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQKZq4O8yTUD"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "executionInfo": {
     "elapsed": 1712,
     "status": "ok",
     "timestamp": 1635516063000,
     "user": {
      "displayName": "Rohan Sawant",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjtxl3WLKLbZ5E1Tx7xWJhVsLDUVq_8IKKl-t4jWQ=s64",
      "userId": "08512062062939018513"
     },
     "user_tz": -330
    },
    "id": "mHKINILqgUfp"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import warnings\n",
    "import re\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tqdm.pandas()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJ_KHZ3gydQM"
   },
   "source": [
    "## Convert m2 data to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "executionInfo": {
     "elapsed": 696,
     "status": "ok",
     "timestamp": 1635516074488,
     "user": {
      "displayName": "Rohan Sawant",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjtxl3WLKLbZ5E1Tx7xWJhVsLDUVq_8IKKl-t4jWQ=s64",
      "userId": "08512062062939018513"
     },
     "user_tz": -330
    },
    "id": "4zzr12B6txpi"
   },
   "outputs": [],
   "source": [
    "#https://www.cl.cam.ac.uk/research/nl/bea2019st/data/corr_from_m2.py\n",
    "def m2_to_df(m2_file_path,id=0):\n",
    "    '''This function takes m2 file path as input and converts it to pandas dataframe'''\n",
    "\n",
    "    m2 = open(m2_file_path).read().strip().split(\"\\n\\n\")\n",
    "    # Do not apply edits with these error types\n",
    "    skip = {\"noop\", \"UNK\", \"Um\"}\n",
    "\n",
    "    correct_sent_array = []\n",
    "    incorrect_sent_array = []\n",
    "\n",
    "    for sent in tqdm(m2):\n",
    "        sent = sent.split(\"\\n\")\n",
    "        incor_sent = sent[0].split()[1:] # Ignore \"S \"\n",
    "        incorrect_sent_array.append(str(' '.join(incor_sent))) \n",
    "        cor_sent = incor_sent.copy()\n",
    "\n",
    "        edits = sent[1:]\n",
    "        offset = 0\n",
    "        for edit in edits:\n",
    "            edit = edit.split(\"|||\")\n",
    "            if edit[1] in skip: continue # Ignore certain edits\n",
    "            coder = int(edit[-1])\n",
    "            if coder != id: continue # Ignore other coders\n",
    "            span = edit[0].split()[1:] # Ignore \"A \"\n",
    "            start = int(span[0])\n",
    "            end = int(span[1])\n",
    "            cor = edit[2].split()\n",
    "            cor_sent[start+offset:end+offset] = cor\n",
    "            offset = offset-(end-start)+len(cor)\n",
    "        correct_sent_array.append(str(' '.join(cor_sent)))\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df[\"correct\"] = correct_sent_array\n",
    "    df[\"incorrect\"] = incorrect_sent_array\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11838,
     "status": "ok",
     "timestamp": 1635516089840,
     "user": {
      "displayName": "Rohan Sawant",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjtxl3WLKLbZ5E1Tx7xWJhVsLDUVq_8IKKl-t4jWQ=s64",
      "userId": "08512062062939018513"
     },
     "user_tz": -330
    },
    "id": "IaDJU7_Sh_7p",
    "outputId": "24cdb85f-6b2c-46f1-9fe4-f1f2b96043b3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 1037561/1037561 [00:02<00:00, 353136.87it/s]\n"
     ]
    }
   ],
   "source": [
    "m2_file = '/Users/saisrivishwanath/Documents/GrammarErrorCorrection/lang8.bea19/lang8.train.auto.bea19.m2'\n",
    "df = m2_to_df(m2_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1635359457703,
     "user": {
      "displayName": "Rohan Sawant",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjtxl3WLKLbZ5E1Tx7xWJhVsLDUVq_8IKKl-t4jWQ=s64",
      "userId": "08512062062939018513"
     },
     "user_tz": -330
    },
    "id": "sFHZUNlIwyll",
    "outputId": "51992832-0170-40d2-c237-b0d2776517b8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>incorrect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>299143</th>\n",
       "      <td>In order to solve this problem ,</td>\n",
       "      <td>For solving this problem ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775957</th>\n",
       "      <td>There is a large lake called Loch Ness in the ...</td>\n",
       "      <td>There is a large lake called the Loch Ness in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399672</th>\n",
       "      <td>And if I want to work abroad , the ability to ...</td>\n",
       "      <td>And if I want to work abroad , an ability to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746981</th>\n",
       "      <td>It has been raining in my area since yesterday...</td>\n",
       "      <td>Yesterday and Today , it is raining in my area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35404</th>\n",
       "      <td>Wow .</td>\n",
       "      <td>Wow .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  correct  \\\n",
       "299143                   In order to solve this problem ,   \n",
       "775957  There is a large lake called Loch Ness in the ...   \n",
       "399672  And if I want to work abroad , the ability to ...   \n",
       "746981  It has been raining in my area since yesterday...   \n",
       "35404                                               Wow .   \n",
       "\n",
       "                                                incorrect  \n",
       "299143                         For solving this problem ,  \n",
       "775957  There is a large lake called the Loch Ness in ...  \n",
       "399672  And if I want to work abroad , an ability to s...  \n",
       "746981  Yesterday and Today , it is raining in my area...  \n",
       "35404                                               Wow .  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "executionInfo": {
     "elapsed": 6177,
     "status": "ok",
     "timestamp": 1635516104493,
     "user": {
      "displayName": "Rohan Sawant",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjtxl3WLKLbZ5E1Tx7xWJhVsLDUVq_8IKKl-t4jWQ=s64",
      "userId": "08512062062939018513"
     },
     "user_tz": -330
    },
    "id": "q7kuNNzEw3yz"
   },
   "outputs": [],
   "source": [
    "df.to_csv('/Users/saisrivishwanath/Documents/GrammarErrorCorrection/git files/GrammarErrorCorrection/df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1037561, 2)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Character and word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['correct_char_count'] = df['correct'].astype('str').apply(lambda x:len(x))\n",
    "df['incorrect_char_count'] = df['incorrect'].astype('str').apply(lambda x:len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['correct_word_count'] = df['correct'].astype('str').apply(lambda x:len(x.split()))\n",
    "df['incorrect_word_count'] = df['incorrect'].astype('str').apply(lambda x:len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>incorrect</th>\n",
       "      <th>correct_char_count</th>\n",
       "      <th>incorrect_char_count</th>\n",
       "      <th>correct_word_count</th>\n",
       "      <th>incorrect_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114440</th>\n",
       "      <td>My best regards .</td>\n",
       "      <td>My best regards .</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687158</th>\n",
       "      <td>But this time I really regret messing up my ch...</td>\n",
       "      <td>But this time I really regret messing up my ch...</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869104</th>\n",
       "      <td>I feel tried to treat it . .</td>\n",
       "      <td>I feel tried to treat it . .</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239255</th>\n",
       "      <td>I was ordered by the company to improve my Eng...</td>\n",
       "      <td>I was ordered by company to improve my English .</td>\n",
       "      <td>52</td>\n",
       "      <td>48</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198006</th>\n",
       "      <td>10 .</td>\n",
       "      <td>10 .</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  correct  \\\n",
       "114440                                  My best regards .   \n",
       "687158  But this time I really regret messing up my ch...   \n",
       "869104                       I feel tried to treat it . .   \n",
       "239255  I was ordered by the company to improve my Eng...   \n",
       "198006                                               10 .   \n",
       "\n",
       "                                                incorrect  correct_char_count  \\\n",
       "114440                                  My best regards .                  17   \n",
       "687158  But this time I really regret messing up my ch...                  69   \n",
       "869104                       I feel tried to treat it . .                  28   \n",
       "239255   I was ordered by company to improve my English .                  52   \n",
       "198006                                               10 .                   4   \n",
       "\n",
       "        incorrect_char_count  correct_word_count  incorrect_word_count  \n",
       "114440                    17                   4                     4  \n",
       "687158                    69                  14                    14  \n",
       "869104                    28                   8                     8  \n",
       "239255                    48                  11                    10  \n",
       "198006                     4                   2                     2  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>correct</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incorrect</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correct_char_count</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incorrect_char_count</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correct_word_count</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incorrect_word_count</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      missing_count\n",
       "correct                           0\n",
       "incorrect                         0\n",
       "correct_char_count                0\n",
       "incorrect_char_count              0\n",
       "correct_word_count                0\n",
       "incorrect_word_count              0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df.isna().sum(),columns=['missing_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>incorrect</th>\n",
       "      <th>correct_char_count</th>\n",
       "      <th>incorrect_char_count</th>\n",
       "      <th>correct_word_count</th>\n",
       "      <th>incorrect_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [correct, incorrect, correct_char_count, incorrect_char_count, correct_word_count, incorrect_word_count]\n",
       "Index: []"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1037561, 6)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>incorrect</th>\n",
       "      <th>correct_char_count</th>\n",
       "      <th>incorrect_char_count</th>\n",
       "      <th>correct_word_count</th>\n",
       "      <th>incorrect_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>457861</th>\n",
       "      <td>The movie 's title is `` Green Zone `` .</td>\n",
       "      <td>Movie 's title is `` Green Zone `` .</td>\n",
       "      <td>40</td>\n",
       "      <td>36</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952728</th>\n",
       "      <td># twinglish</td>\n",
       "      <td># twinglish</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186064</th>\n",
       "      <td>I 'm looking for a language exchange friend .</td>\n",
       "      <td>I 'm finding language exchange friend . .</td>\n",
       "      <td>45</td>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979921</th>\n",
       "      <td>I 'm planning to travel !</td>\n",
       "      <td>I 'm planning to travel !</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412865</th>\n",
       "      <td>So , she is a great mother , and I admire her .</td>\n",
       "      <td>so , she is a great mother , I admire she .</td>\n",
       "      <td>47</td>\n",
       "      <td>43</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                correct  \\\n",
       "457861         The movie 's title is `` Green Zone `` .   \n",
       "952728                                      # twinglish   \n",
       "186064    I 'm looking for a language exchange friend .   \n",
       "979921                        I 'm planning to travel !   \n",
       "412865  So , she is a great mother , and I admire her .   \n",
       "\n",
       "                                          incorrect  correct_char_count  \\\n",
       "457861         Movie 's title is `` Green Zone `` .                  40   \n",
       "952728                                  # twinglish                  11   \n",
       "186064    I 'm finding language exchange friend . .                  45   \n",
       "979921                    I 'm planning to travel !                  25   \n",
       "412865  so , she is a great mother , I admire she .                  47   \n",
       "\n",
       "        incorrect_char_count  correct_word_count  incorrect_word_count  \n",
       "457861                    36                  10                     9  \n",
       "952728                    11                   2                     2  \n",
       "186064                    41                   9                     8  \n",
       "979921                    25                   6                     6  \n",
       "412865                    43                  13                    12  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of duplicate pairs: 539202\n"
     ]
    }
   ],
   "source": [
    "print(f\"total number of duplicate pairs: {len(df[df['correct']==df['incorrect']])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of duplicate pairs: 539202\n"
     ]
    }
   ],
   "source": [
    "print(f\"total number of duplicate pairs: {len(df[df['correct']==df['incorrect']])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>incorrect</th>\n",
       "      <th>correct_char_count</th>\n",
       "      <th>incorrect_char_count</th>\n",
       "      <th>correct_word_count</th>\n",
       "      <th>incorrect_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>333593</th>\n",
       "      <td>Then , do you like to eat cup - ramyeons , or ...</td>\n",
       "      <td>Then , do you like to eat cup - ramyeons , or ...</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016241</th>\n",
       "      <td>I strolled to the kitchen and went up to the k...</td>\n",
       "      <td>I strolled to the kitchen and went up to the k...</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747764</th>\n",
       "      <td>I have to work until 9 : 30 am .</td>\n",
       "      <td>I have to work until 9 : 30 am .</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195733</th>\n",
       "      <td>He is talented .</td>\n",
       "      <td>He is talented .</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502768</th>\n",
       "      <td>Handsome guy</td>\n",
       "      <td>Handsome guy</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606427</th>\n",
       "      <td>For beer garden , it was so much fun too ! !</td>\n",
       "      <td>For beer garden , it was so much fun too ! !</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923940</th>\n",
       "      <td>Worship had been by screen without a real past...</td>\n",
       "      <td>Worship had been by screen without a real past...</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387184</th>\n",
       "      <td>cherry blossoms</td>\n",
       "      <td>cherry blossoms</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251119</th>\n",
       "      <td>If you do it you will see the results , if you...</td>\n",
       "      <td>If you do it you will see the results , if you...</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328793</th>\n",
       "      <td>However , it 's too difficult for me to do the...</td>\n",
       "      <td>However , it 's too difficult for me to do the...</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   correct  \\\n",
       "333593   Then , do you like to eat cup - ramyeons , or ...   \n",
       "1016241  I strolled to the kitchen and went up to the k...   \n",
       "747764                    I have to work until 9 : 30 am .   \n",
       "195733                                    He is talented .   \n",
       "502768                                        Handsome guy   \n",
       "606427        For beer garden , it was so much fun too ! !   \n",
       "923940   Worship had been by screen without a real past...   \n",
       "387184                                     cherry blossoms   \n",
       "251119   If you do it you will see the results , if you...   \n",
       "328793   However , it 's too difficult for me to do the...   \n",
       "\n",
       "                                                 incorrect  \\\n",
       "333593   Then , do you like to eat cup - ramyeons , or ...   \n",
       "1016241  I strolled to the kitchen and went up to the k...   \n",
       "747764                    I have to work until 9 : 30 am .   \n",
       "195733                                    He is talented .   \n",
       "502768                                        Handsome guy   \n",
       "606427        For beer garden , it was so much fun too ! !   \n",
       "923940   Worship had been by screen without a real past...   \n",
       "387184                                     cherry blossoms   \n",
       "251119   If you do it you will see the results , if you...   \n",
       "328793   However , it 's too difficult for me to do the...   \n",
       "\n",
       "         correct_char_count  incorrect_char_count  correct_word_count  \\\n",
       "333593                   62                    62                  16   \n",
       "1016241                  53                    53                  12   \n",
       "747764                   32                    32                  10   \n",
       "195733                   16                    16                   4   \n",
       "502768                   12                    12                   2   \n",
       "606427                   44                    44                  12   \n",
       "923940                   50                    50                  10   \n",
       "387184                   15                    15                   2   \n",
       "251119                   69                    69                  18   \n",
       "328793                   50                    50                  12   \n",
       "\n",
       "         incorrect_word_count  \n",
       "333593                     16  \n",
       "1016241                    12  \n",
       "747764                     10  \n",
       "195733                      4  \n",
       "502768                      2  \n",
       "606427                     12  \n",
       "923940                     10  \n",
       "387184                      2  \n",
       "251119                     18  \n",
       "328793                     12  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['correct']==df['incorrect']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['correct']!=df['incorrect']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498359, 6)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>incorrect</th>\n",
       "      <th>correct_char_count</th>\n",
       "      <th>incorrect_char_count</th>\n",
       "      <th>correct_word_count</th>\n",
       "      <th>incorrect_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44297</th>\n",
       "      <td>But he only stayed there 5 weeks and said that...</td>\n",
       "      <td>But he said a 5 - weeks was too short .</td>\n",
       "      <td>65</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864999</th>\n",
       "      <td>Properly speaking , they refuse to be so .</td>\n",
       "      <td>Exactly speaking , they refuse to be so .</td>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546778</th>\n",
       "      <td>I have been bedridden for the past two days , ...</td>\n",
       "      <td>I lie down all the days long in these 2 days ,...</td>\n",
       "      <td>125</td>\n",
       "      <td>123</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751003</th>\n",
       "      <td>I was able to see my friends and was pursued b...</td>\n",
       "      <td>I could meet my friends and was courted by Meg...</td>\n",
       "      <td>58</td>\n",
       "      <td>53</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911014</th>\n",
       "      <td>We Japanese tend to not look into the eyes of ...</td>\n",
       "      <td>We Japanese tend not to look into eyes of othe...</td>\n",
       "      <td>83</td>\n",
       "      <td>85</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  correct  \\\n",
       "44297   But he only stayed there 5 weeks and said that...   \n",
       "864999         Properly speaking , they refuse to be so .   \n",
       "546778  I have been bedridden for the past two days , ...   \n",
       "751003  I was able to see my friends and was pursued b...   \n",
       "911014  We Japanese tend to not look into the eyes of ...   \n",
       "\n",
       "                                                incorrect  correct_char_count  \\\n",
       "44297             But he said a 5 - weeks was too short .                  65   \n",
       "864999          Exactly speaking , they refuse to be so .                  42   \n",
       "546778  I lie down all the days long in these 2 days ,...                 125   \n",
       "751003  I could meet my friends and was courted by Meg...                  58   \n",
       "911014  We Japanese tend not to look into eyes of othe...                  83   \n",
       "\n",
       "        incorrect_char_count  correct_word_count  incorrect_word_count  \n",
       "44297                     39                  15                    11  \n",
       "864999                    41                   9                     9  \n",
       "546778                   123                  27                    28  \n",
       "751003                    53                  14                    12  \n",
       "911014                    85                  18                    18  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of duplicates: 2021\n"
     ]
    }
   ],
   "source": [
    "print(f'total number of duplicates: {df.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>incorrect</th>\n",
       "      <th>correct_char_count</th>\n",
       "      <th>incorrect_char_count</th>\n",
       "      <th>correct_word_count</th>\n",
       "      <th>incorrect_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>717380</th>\n",
       "      <td>( I seriously want to escape , all the way , t...</td>\n",
       "      <td>( I seriously want to escape , all the way , t...</td>\n",
       "      <td>88</td>\n",
       "      <td>85</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027463</th>\n",
       "      <td>( I seriously want to escape , all the way , t...</td>\n",
       "      <td>( I seriously want to escape , all the way , t...</td>\n",
       "      <td>88</td>\n",
       "      <td>85</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802136</th>\n",
       "      <td>: - )</td>\n",
       "      <td>: - (</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800389</th>\n",
       "      <td>: - )</td>\n",
       "      <td>: - (</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161743</th>\n",
       "      <td>A : How much did it cost ?</td>\n",
       "      <td>A : How much does is cost ?</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350828</th>\n",
       "      <td>to be continued . . .</td>\n",
       "      <td>to be continue . . .</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17343</th>\n",
       "      <td>to be continued . . .</td>\n",
       "      <td>to be continue . . .</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633236</th>\n",
       "      <td>to be continued . . .</td>\n",
       "      <td>to be continue . . .</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767285</th>\n",
       "      <td>today was a bad day .</td>\n",
       "      <td>today is a bad day .</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223151</th>\n",
       "      <td>today was a bad day .</td>\n",
       "      <td>today is a bad day .</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3129 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   correct  \\\n",
       "717380   ( I seriously want to escape , all the way , t...   \n",
       "1027463  ( I seriously want to escape , all the way , t...   \n",
       "802136                                               : - )   \n",
       "800389                                               : - )   \n",
       "161743                          A : How much did it cost ?   \n",
       "...                                                    ...   \n",
       "350828                               to be continued . . .   \n",
       "17343                                to be continued . . .   \n",
       "633236                               to be continued . . .   \n",
       "767285                               today was a bad day .   \n",
       "223151                               today was a bad day .   \n",
       "\n",
       "                                                 incorrect  \\\n",
       "717380   ( I seriously want to escape , all the way , t...   \n",
       "1027463  ( I seriously want to escape , all the way , t...   \n",
       "802136                                               : - (   \n",
       "800389                                               : - (   \n",
       "161743                         A : How much does is cost ?   \n",
       "...                                                    ...   \n",
       "350828                                to be continue . . .   \n",
       "17343                                 to be continue . . .   \n",
       "633236                                to be continue . . .   \n",
       "767285                                today is a bad day .   \n",
       "223151                                today is a bad day .   \n",
       "\n",
       "         correct_char_count  incorrect_char_count  correct_word_count  \\\n",
       "717380                   88                    85                  19   \n",
       "1027463                  88                    85                  19   \n",
       "802136                    5                     5                   3   \n",
       "800389                    5                     5                   3   \n",
       "161743                   26                    27                   8   \n",
       "...                     ...                   ...                 ...   \n",
       "350828                   21                    20                   6   \n",
       "17343                    21                    20                   6   \n",
       "633236                   21                    20                   6   \n",
       "767285                   21                    20                   6   \n",
       "223151                   21                    20                   6   \n",
       "\n",
       "         incorrect_word_count  \n",
       "717380                     19  \n",
       "1027463                    19  \n",
       "802136                      3  \n",
       "800389                      3  \n",
       "161743                      8  \n",
       "...                       ...  \n",
       "350828                      6  \n",
       "17343                       6  \n",
       "633236                      6  \n",
       "767285                      6  \n",
       "223151                      6  \n",
       "\n",
       "[3129 rows x 6 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated(keep=False)].sort_values('correct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(496338, 6)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>incorrect</th>\n",
       "      <th>correct_char_count</th>\n",
       "      <th>incorrect_char_count</th>\n",
       "      <th>correct_word_count</th>\n",
       "      <th>incorrect_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>430830</th>\n",
       "      <td>I ca n't believe time goes by so fast .</td>\n",
       "      <td>I ca n't believe time is so fast .</td>\n",
       "      <td>39</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483161</th>\n",
       "      <td>Now , I am free - lance .</td>\n",
       "      <td>Now , I am free job .</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423637</th>\n",
       "      <td>It is not easy but I enjoy it .</td>\n",
       "      <td>It is not easy but enjoying .</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283036</th>\n",
       "      <td>A lot of drinking Beer , syotyu and kakutel .</td>\n",
       "      <td>A lot of drink a Beer , syotyu and kakutel .</td>\n",
       "      <td>45</td>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380087</th>\n",
       "      <td>I 'm not good at Physics .</td>\n",
       "      <td>I 'm not good at physics .</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              correct  \\\n",
       "430830        I ca n't believe time goes by so fast .   \n",
       "483161                      Now , I am free - lance .   \n",
       "423637                It is not easy but I enjoy it .   \n",
       "283036  A lot of drinking Beer , syotyu and kakutel .   \n",
       "380087                     I 'm not good at Physics .   \n",
       "\n",
       "                                           incorrect  correct_char_count  \\\n",
       "430830            I ca n't believe time is so fast .                  39   \n",
       "483161                         Now , I am free job .                  25   \n",
       "423637                 It is not easy but enjoying .                  31   \n",
       "283036  A lot of drink a Beer , syotyu and kakutel .                  45   \n",
       "380087                    I 'm not good at physics .                  26   \n",
       "\n",
       "        incorrect_char_count  correct_word_count  incorrect_word_count  \n",
       "430830                    34                  10                     9  \n",
       "483161                    21                   8                     7  \n",
       "423637                    29                   9                     7  \n",
       "283036                    44                  10                    11  \n",
       "380087                    26                   7                     7  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing small texts(sentences whose length is less than 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 6)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['correct_char_count']<2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>incorrect</th>\n",
       "      <th>correct_char_count</th>\n",
       "      <th>incorrect_char_count</th>\n",
       "      <th>correct_word_count</th>\n",
       "      <th>incorrect_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>465170</th>\n",
       "      <td>.</td>\n",
       "      <td>life .</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251783</th>\n",
       "      <td>.</td>\n",
       "      <td>out .</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153480</th>\n",
       "      <td>.</td>\n",
       "      <td>For Tech support .</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113363</th>\n",
       "      <td>.</td>\n",
       "      <td>M .</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461060</th>\n",
       "      <td>.</td>\n",
       "      <td>had them .</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10489</th>\n",
       "      <td>.</td>\n",
       "      <td>took some medicine .</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398158</th>\n",
       "      <td>.</td>\n",
       "      <td>them .</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439421</th>\n",
       "      <td>.</td>\n",
       "      <td>on face .</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480724</th>\n",
       "      <td>.</td>\n",
       "      <td>or philosopher movie .</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164090</th>\n",
       "      <td>?</td>\n",
       "      <td>' ? ?</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       correct               incorrect  correct_char_count  \\\n",
       "465170       .                  life .                   1   \n",
       "251783       .                   out .                   1   \n",
       "153480       .      For Tech support .                   1   \n",
       "113363       .                     M .                   1   \n",
       "461060       .              had them .                   1   \n",
       "10489        .    took some medicine .                   1   \n",
       "398158       .                  them .                   1   \n",
       "439421       .               on face .                   1   \n",
       "480724       .  or philosopher movie .                   1   \n",
       "164090       ?                   ' ? ?                   1   \n",
       "\n",
       "        incorrect_char_count  correct_word_count  incorrect_word_count  \n",
       "465170                     6                   1                     2  \n",
       "251783                     5                   1                     2  \n",
       "153480                    18                   1                     4  \n",
       "113363                     3                   1                     2  \n",
       "461060                    10                   1                     3  \n",
       "10489                     20                   1                     4  \n",
       "398158                     6                   1                     2  \n",
       "439421                     9                   1                     3  \n",
       "480724                    22                   1                     4  \n",
       "164090                     5                   1                     3  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['correct_char_count']<2].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['correct_char_count']>2].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(496299, 6)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.analyticsvidhya.com/blog/2020/04/beginners-guide-exploratory-data-analysis-text-data/\n",
    "contractions_dict = { \"ain't\": \"are not\",\"'s\":\" is\",\"aren't\": \"are not\",\n",
    "                     \"can't\": \"cannot\",\"can't've\": \"cannot have\",\n",
    "                     \"'cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\",\n",
    "                     \"couldn't've\": \"could not have\", \"didn't\": \"did not\",\"doesn't\": \"does not\",\n",
    "                     \"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\n",
    "                     \"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he would\",\n",
    "                     \"he'd've\": \"he would have\",\"he'll\": \"he will\", \"he'll've\": \"he will have\",\n",
    "                     \"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\n",
    "                     \"I'd\": \"I would\", \"I'd've\": \"I would have\",\"I'll\": \"I will\",\n",
    "                     \"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\", \"isn't\": \"is not\",\n",
    "                     \"it'd\": \"it would\",\"it'd've\": \"it would have\",\"it'll\": \"it will\",\n",
    "                     \"it'll've\": \"it will have\", \"let's\": \"let us\",\"ma'am\": \"madam\",\n",
    "                     \"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\", \n",
    "                     \"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\n",
    "                     \"mustn't've\": \"must not have\", \"needn't\": \"need not\",\n",
    "                     \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\n",
    "                     \"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\n",
    "                     \"shan't've\": \"shall not have\",\"she'd\": \"she would\",\"she'd've\": \"she would have\",\n",
    "                     \"she'll\": \"she will\", \"she'll've\": \"she will have\",\"should've\": \"should have\",\n",
    "                     \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\"so've\": \"so have\",\n",
    "                     \"that'd\": \"that would\",\"that'd've\": \"that would have\", \"there'd\": \"there would\",\n",
    "                     \"there'd've\": \"there would have\", \"they'd\": \"they would\",\n",
    "                     \"they'd've\": \"they would have\",\"they'll\": \"they will\",\n",
    "                     \"they'll've\": \"they will have\", \"they're\": \"they are\",\"they've\": \"they have\",\n",
    "                     \"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we would\",\n",
    "                     \"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\n",
    "                     \"we're\": \"we are\",\"we've\": \"we have\", \"weren't\": \"were not\",\"what'll\": \"what will\",\n",
    "                     \"what'll've\": \"what will have\",\"what're\": \"what are\", \"what've\": \"what have\",\n",
    "                     \"when've\": \"when have\",\"where'd\": \"where did\", \"where've\": \"where have\",\n",
    "                     \"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who've\": \"who have\",\n",
    "                     \"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\n",
    "                     \"won't've\": \"will not have\", \"would've\": \"would have\",\"wouldn't\": \"would not\",\n",
    "                     \"wouldn't've\": \"would not have\",\"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                     \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n",
    "                     \"y'all've\": \"you all have\", \"you'd\": \"you would\",\"you'd've\": \"you would have\",\n",
    "                     \"you'll\": \"you will\",\"you'll've\": \"you will have\", \"you're\": \"you are\",\n",
    "                     \"you've\": \"you have\",\"n\\'t\":\" not\",\"\\'re\":\" are\",\"\\'s\": \" is\",\"\\'d\":\" would\",\n",
    "                     \"\\'ll\": \" will\",\"\\'t\":\" not\",\"\\'ve\": \" have\",\"\\'m\":\" am\"}\n",
    "\n",
    "\n",
    "# Regular expression for finding contractions\n",
    "contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "\n",
    "# Function for expanding contractions\n",
    "def expand_contractions(text,contractions_dict=contractions_dict):\n",
    "    def replace(match):\n",
    "        return contractions_dict[match.group(0)]\n",
    "    return contractions_re.sub(replace, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/47091490/4084039\n",
    "def clean(text):\n",
    "    text = re.sub('\\s*\\<.*?\\>\\s', '', text)\n",
    "    text = re.sub('\\s*\\(.*?\\)\\s', '', text)\n",
    "    text = re.sub('\\s*\\[.*?\\]\\s', '', text)\n",
    "    text = re.sub('\\s*\\{.*?\\}\\s', '', text)\n",
    "    text = re.sub(\"[-+@#^/|*(){}$~<>=_%:;]\",\"\",text)\n",
    "    text = text.replace(\"\\\\\",\"\")\n",
    "    text = re.sub(\"\\[\",\"\",text)\n",
    "    text = re.sub(\"\\]\",\"\",text)\n",
    "    text = re.sub(\"\\<\",\"\",text)\n",
    "    text = re.sub(\"\\>\",\"\",text)\n",
    "    text = re.sub(\"\\(\",\"\",text)\n",
    "    text = re.sub(\"\\)\",\"\",text)\n",
    "    text = re.sub(\"[0-9]\",\"\",text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 496299/496299 [00:05<00:00, 97551.77it/s]\n",
      "100%|████████████████████████████████| 496299/496299 [00:06<00:00, 72454.82it/s]\n"
     ]
    }
   ],
   "source": [
    "df['correct'] = df['correct'].progress_apply(clean)\n",
    "df['correct'] = df['correct'].progress_apply(expand_contractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 496299/496299 [00:04<00:00, 99390.99it/s]\n",
      "100%|████████████████████████████████| 496299/496299 [00:06<00:00, 74261.03it/s]\n"
     ]
    }
   ],
   "source": [
    "df['incorrect'] = df['incorrect'].progress_apply(clean)\n",
    "df['incorrect'] = df['incorrect'].progress_apply(expand_contractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>incorrect</th>\n",
       "      <th>correct_char_count</th>\n",
       "      <th>incorrect_char_count</th>\n",
       "      <th>correct_word_count</th>\n",
       "      <th>incorrect_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71816</th>\n",
       "      <td>I write about two or three mails a day .</td>\n",
       "      <td>I make about two or three mails in a day .</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482897</th>\n",
       "      <td>In the past when I was a kid , I wanted to go ...</td>\n",
       "      <td>in past when kid , I want go good school , but...</td>\n",
       "      <td>99</td>\n",
       "      <td>69</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173839</th>\n",
       "      <td>The J league will cover only one more game bef...</td>\n",
       "      <td>The J league will over only one game before a ...</td>\n",
       "      <td>104</td>\n",
       "      <td>83</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273983</th>\n",
       "      <td>One of my American friends gave me a new phras...</td>\n",
       "      <td>One of my American friends gave me a new word ...</td>\n",
       "      <td>73</td>\n",
       "      <td>71</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187603</th>\n",
       "      <td>I feel bad . or I feel ill .</td>\n",
       "      <td>I feel bad .</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  correct  \\\n",
       "71816            I write about two or three mails a day .   \n",
       "482897  In the past when I was a kid , I wanted to go ...   \n",
       "173839  The J league will cover only one more game bef...   \n",
       "273983  One of my American friends gave me a new phras...   \n",
       "187603                       I feel bad . or I feel ill .   \n",
       "\n",
       "                                                incorrect  correct_char_count  \\\n",
       "71816          I make about two or three mails in a day .                  40   \n",
       "482897  in past when kid , I want go good school , but...                  99   \n",
       "173839  The J league will over only one game before a ...                 104   \n",
       "273983  One of my American friends gave me a new word ...                  73   \n",
       "187603                                       I feel bad .                  28   \n",
       "\n",
       "        incorrect_char_count  correct_word_count  incorrect_word_count  \n",
       "71816                     42                  10                    11  \n",
       "482897                    69                  25                    17  \n",
       "173839                    83                  20                    16  \n",
       "273983                    71                  16                    16  \n",
       "187603                    12                   9                     4  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/Users/saisrivishwanath/Documents/GrammarErrorCorrection/git files/GrammarErrorCorrection/preprocessed_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(496299, 6)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = df[df['incorrect_word_count'] <= 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('/Users/saisrivishwanath/Documents/GrammarErrorCorrection/git files/GrammarErrorCorrection/final_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language Vocabulary Builder for Seq2Seq Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2 \n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting Unicode Strings to ASCII and Normalizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and Process Language Pairs from the data(CSV File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, filename, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    df = pd.read_csv('preprocessed_df.csv')\n",
    "    df = df.dropna(subset=['incorrect', 'correct'])\n",
    "  \n",
    "    pairs = list(zip(df['incorrect'], df['correct']))\n",
    "\n",
    "    pairs = [[normalizeString(s) for s in pair] for pair in pairs]\n",
    "\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2) \n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering Sentence Pairs for Maximum Length Constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 12\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 496255 sentence pairs\n",
      "Trimmed to 266109 sentence pairs\n",
      "Counting words...\n",
      "length of first 50000 pairs 50000\n",
      "Counted words:\n",
      "eng 60326\n",
      "eng 49505\n",
      "['I felt I need to study !', 'I felt like I needed to study more !']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    pairs = pairs[0:50000]\n",
    "    print(\"length of first 50000 pairs\", len(pairs))\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'eng', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "print(len(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'And': 2,\n",
       " 'he': 3,\n",
       " 'took': 4,\n",
       " 'in': 5,\n",
       " 'my': 6,\n",
       " 'favorite': 7,\n",
       " 'subject': 8,\n",
       " 'like': 9,\n",
       " 'soccer': 10,\n",
       " 'Actually': 11,\n",
       " 'who': 12,\n",
       " 'let': 13,\n",
       " 'me': 14,\n",
       " 'know': 15,\n",
       " 'about': 16,\n",
       " 'Lang': 17,\n",
       " 'was': 18,\n",
       " 'him': 19,\n",
       " 'His': 20,\n",
       " 'Kanji': 21,\n",
       " 'is': 22,\n",
       " 'ability': 23,\n",
       " 'much': 24,\n",
       " 'better': 25,\n",
       " 'than': 26,\n",
       " 'I': 27,\n",
       " 'heard': 28,\n",
       " 'a': 29,\n",
       " 'sentence': 30,\n",
       " 'last': 31,\n",
       " 'night': 32,\n",
       " 'when': 33,\n",
       " 'watched': 34,\n",
       " 'TV': 35,\n",
       " 'When': 36,\n",
       " 'you': 37,\n",
       " 'go': 38,\n",
       " 'uphill': 39,\n",
       " 'hvae': 40,\n",
       " 'to': 41,\n",
       " 'bend': 42,\n",
       " 'your': 43,\n",
       " 'back': 44,\n",
       " 'are': 45,\n",
       " 'smoothly': 46,\n",
       " 'have': 47,\n",
       " 'be': 48,\n",
       " 'more': 49,\n",
       " 'modest': 50,\n",
       " 'The': 51,\n",
       " 'making': 52,\n",
       " 'souvenir': 53,\n",
       " 'hard': 54,\n",
       " 'and': 55,\n",
       " 'interesting': 56,\n",
       " 'work': 57,\n",
       " 'You': 58,\n",
       " 'can': 59,\n",
       " 'take': 60,\n",
       " 'them': 61,\n",
       " 'at': 62,\n",
       " 'slot': 63,\n",
       " 'machine': 64,\n",
       " 'third': 65,\n",
       " 'memory': 66,\n",
       " 'the': 67,\n",
       " 'house': 68,\n",
       " 'we': 69,\n",
       " 'lived': 70,\n",
       " 'Do': 71,\n",
       " 'not': 72,\n",
       " 'why': 73,\n",
       " 'liked': 74,\n",
       " 'winter': 75,\n",
       " 'Finland': 76,\n",
       " 'hope': 77,\n",
       " 'summer': 78,\n",
       " 'If': 79,\n",
       " 'only': 80,\n",
       " 'had': 81,\n",
       " 'black': 82,\n",
       " 'dense': 83,\n",
       " 'curtains': 84,\n",
       " 'been': 85,\n",
       " 'wondering': 86,\n",
       " 'what': 87,\n",
       " 'she': 88,\n",
       " 'doing': 89,\n",
       " 'It': 90,\n",
       " 'said': 91,\n",
       " 'that': 92,\n",
       " 'disappointing': 93,\n",
       " 'Old': 94,\n",
       " 'beautiful': 95,\n",
       " 'Still': 96,\n",
       " 'has': 97,\n",
       " 'recovered': 98,\n",
       " 'from': 99,\n",
       " '?': 100,\n",
       " 'OK': 101,\n",
       " 'all': 102,\n",
       " 'for': 103,\n",
       " 'first': 104,\n",
       " 'entry': 105,\n",
       " 'Before': 106,\n",
       " 'went': 107,\n",
       " 'library': 108,\n",
       " 'On': 109,\n",
       " 'way': 110,\n",
       " 'headache': 111,\n",
       " 'sentences': 112,\n",
       " 'practical': 113,\n",
       " 'correct': 114,\n",
       " 'Well': 115,\n",
       " 'there': 116,\n",
       " 'remains': 117,\n",
       " 'get': 118,\n",
       " 'it': 119,\n",
       " 'check': 120,\n",
       " 'out': 121,\n",
       " 'Cooking': 122,\n",
       " 'her': 123,\n",
       " 'profession': 124,\n",
       " 'housewife': 125,\n",
       " 'rather': 126,\n",
       " 'working': 127,\n",
       " 'outside': 128,\n",
       " 'think': 129,\n",
       " 'one': 130,\n",
       " 'half': 131,\n",
       " 'year': 132,\n",
       " 'This': 133,\n",
       " 'time': 134,\n",
       " 'write': 135,\n",
       " 'diary': 136,\n",
       " 'on': 137,\n",
       " 'internet': 138,\n",
       " 'someone': 139,\n",
       " 'see': 140,\n",
       " 'DVD': 141,\n",
       " 'Grey': 142,\n",
       " 'anatomy': 143,\n",
       " 'today': 144,\n",
       " 'keep': 145,\n",
       " 'watching': 146,\n",
       " 'these': 147,\n",
       " 'days': 148,\n",
       " 'So': 149,\n",
       " 'lot': 150,\n",
       " 'do': 151,\n",
       " 'medical': 152,\n",
       " 'word': 153,\n",
       " 'English': 154,\n",
       " 'very': 155,\n",
       " 'But': 156,\n",
       " 'study': 157,\n",
       " 'through': 158,\n",
       " 'this': 159,\n",
       " 'fun': 160,\n",
       " 'right': 161,\n",
       " 'am': 162,\n",
       " 'eating': 163,\n",
       " 'banana': 164,\n",
       " 'every': 165,\n",
       " 'day': 166,\n",
       " 'health': 167,\n",
       " 'gather': 168,\n",
       " 'stomach': 169,\n",
       " 'gives': 170,\n",
       " 'energy': 171,\n",
       " 'will': 172,\n",
       " 'introduce': 173,\n",
       " 'dog': 174,\n",
       " 'Tiara': 175,\n",
       " 'She': 176,\n",
       " 'golden': 177,\n",
       " 'retriever': 178,\n",
       " 'years': 179,\n",
       " 'old': 180,\n",
       " 'Her': 181,\n",
       " 'fur': 182,\n",
       " 'amber': 183,\n",
       " 'soft': 184,\n",
       " 'basking': 185,\n",
       " 'looks': 186,\n",
       " 'comfortable': 187,\n",
       " 'saw': 188,\n",
       " 'news': 189,\n",
       " 'Yahoo': 190,\n",
       " 'yesterday': 191,\n",
       " 'Here': 192,\n",
       " 'link': 193,\n",
       " 'By': 194,\n",
       " 'contrast': 195,\n",
       " 'men': 196,\n",
       " 'eastern': 197,\n",
       " 'countries': 198,\n",
       " 'most': 199,\n",
       " 'dress': 200,\n",
       " 'up': 201,\n",
       " 'Except': 202,\n",
       " 'shirt': 203,\n",
       " 'jean': 204,\n",
       " 'usually': 205,\n",
       " 'wear': 206,\n",
       " 'an': 207,\n",
       " 'accessory': 208,\n",
       " 'almost': 209,\n",
       " 'cost': 210,\n",
       " 'whole': 211,\n",
       " 'morning': 212,\n",
       " 'watch': 213,\n",
       " 'NBA': 214,\n",
       " 'final': 215,\n",
       " 'game': 216,\n",
       " 'give': 217,\n",
       " 'any': 218,\n",
       " 'commets': 219,\n",
       " 'opinoins': 220,\n",
       " 'too': 221,\n",
       " 'really': 222,\n",
       " 'discuss': 223,\n",
       " 'My': 224,\n",
       " 'son': 225,\n",
       " 'diarrhea': 226,\n",
       " 'warter': 227,\n",
       " 'hip': 228,\n",
       " 'became': 229,\n",
       " 'red': 230,\n",
       " 'Tomorrow': 231,\n",
       " 'hometown': 232,\n",
       " 'We': 233,\n",
       " 'ready': 234,\n",
       " 'cancei': 235,\n",
       " 'no': 236,\n",
       " 'listening': 237,\n",
       " 'music': 238,\n",
       " 'with': 239,\n",
       " 'commuter': 240,\n",
       " 'train': 241,\n",
       " 'warm': 242,\n",
       " 'season': 243,\n",
       " 'so': 244,\n",
       " 'spring': 245,\n",
       " 'Spring': 246,\n",
       " 'exciting': 247,\n",
       " 'Japanese': 248,\n",
       " 'school': 249,\n",
       " 'starts': 250,\n",
       " 'quarifications': 251,\n",
       " 'english': 252,\n",
       " 'new': 253,\n",
       " 'promotions': 254,\n",
       " 'Everyday': 255,\n",
       " 'thinngs': 256,\n",
       " 'try': 257,\n",
       " 'No': 258,\n",
       " 'extremely': 259,\n",
       " 'sometimes': 260,\n",
       " 'Today': 261,\n",
       " 'nothing': 262,\n",
       " 'specal': 263,\n",
       " '!': 264,\n",
       " 'kind': 265,\n",
       " 'of': 266,\n",
       " 'Tai': 267,\n",
       " 'wan': 268,\n",
       " 'stayle': 269,\n",
       " 'massage': 270,\n",
       " 'feel': 271,\n",
       " 'relax': 272,\n",
       " 'bedrock': 273,\n",
       " 'bath': 274,\n",
       " 'Sendai': 275,\n",
       " 'business': 276,\n",
       " 'trip': 277,\n",
       " 'special': 278,\n",
       " 'product': 279,\n",
       " 'cow': 280,\n",
       " 'tongue': 281,\n",
       " 'bought': 282,\n",
       " 'ate': 283,\n",
       " 'home': 284,\n",
       " 'want': 285,\n",
       " 'eat': 286,\n",
       " 'its': 287,\n",
       " 'again': 288,\n",
       " 'daughter': 289,\n",
       " 'woken': 290,\n",
       " 'by': 291,\n",
       " 'wife': 292,\n",
       " 'stertor': 293,\n",
       " 'live': 294,\n",
       " 'life': 295,\n",
       " 'own': 296,\n",
       " 'pace': 297,\n",
       " 'Because': 298,\n",
       " 'finished': 299,\n",
       " 'classes': 300,\n",
       " 'homeworks': 301,\n",
       " 'or': 302,\n",
       " 'jobs': 303,\n",
       " 'etc': 304,\n",
       " 'nearly': 305,\n",
       " 'pm': 306,\n",
       " 'nearlly': 307,\n",
       " 'These': 308,\n",
       " 'suffered': 309,\n",
       " 'many': 310,\n",
       " 'unhappy': 311,\n",
       " 'things': 312,\n",
       " 'how': 313,\n",
       " 'master': 314,\n",
       " 'language': 315,\n",
       " 'well': 316,\n",
       " 'Summer': 317,\n",
       " 'holiday': 318,\n",
       " 'long': 319,\n",
       " 'breaktime': 320,\n",
       " 'should': 321,\n",
       " 'got': 322,\n",
       " 'thirty': 323,\n",
       " 'past': 324,\n",
       " 'Japan': 325,\n",
       " 'make': 326,\n",
       " 'friends': 327,\n",
       " 'lang': 328,\n",
       " 'thank': 329,\n",
       " 'everyone': 330,\n",
       " 'Election': 331,\n",
       " 'done': 332,\n",
       " 'Augst': 333,\n",
       " 'Mayer': 334,\n",
       " 'cheering': 335,\n",
       " 'Hamada': 336,\n",
       " 'minister': 337,\n",
       " 'defence': 338,\n",
       " 'birong': 339,\n",
       " 'Liberal': 340,\n",
       " 'Democratic': 341,\n",
       " 'Party': 342,\n",
       " 'they': 343,\n",
       " 'may': 344,\n",
       " 'lost': 345,\n",
       " 'adoministration': 346,\n",
       " 'supporters': 347,\n",
       " 'Kanazawa': 348,\n",
       " 'university': 349,\n",
       " 'festival': 350,\n",
       " 'American': 351,\n",
       " 'friend': 352,\n",
       " 'made': 353,\n",
       " 'good': 354,\n",
       " 'Vietnamese': 355,\n",
       " 'enjoyed': 356,\n",
       " 'dinner': 357,\n",
       " 'another': 358,\n",
       " 'amazing': 359,\n",
       " 'spnge': 360,\n",
       " 'cute': 361,\n",
       " 'two': 362,\n",
       " 'worries': 363,\n",
       " 'One': 364,\n",
       " 'clumsy': 365,\n",
       " 'yet': 366,\n",
       " 'Another': 367,\n",
       " 'high': 368,\n",
       " 'priced': 369,\n",
       " 'tuition': 370,\n",
       " 'Berklee': 371,\n",
       " 'requires': 372,\n",
       " 'TOEFL': 373,\n",
       " 'score': 374,\n",
       " 'Many': 375,\n",
       " 'assignments': 376,\n",
       " 'given': 377,\n",
       " 'everyday': 378,\n",
       " 'still': 379,\n",
       " 'A': 380,\n",
       " 'review': 381,\n",
       " 'best': 382,\n",
       " 'start': 383,\n",
       " 'point': 384,\n",
       " 'Both': 385,\n",
       " 'merits': 386,\n",
       " 'disadvantages': 387,\n",
       " 'writers': 388,\n",
       " 'Naoki': 389,\n",
       " 'Urasawaand': 390,\n",
       " 'Hiroya': 391,\n",
       " 'Oku': 392,\n",
       " 'doubt': 393,\n",
       " 'illegal': 394,\n",
       " 'experience': 395,\n",
       " 'educational': 396,\n",
       " 'Diagnosed': 397,\n",
       " 'being': 398,\n",
       " 'easily': 399,\n",
       " 'impressed': 400,\n",
       " 'Indian': 401,\n",
       " 'movies': 402,\n",
       " 'same': 403,\n",
       " 'basic': 404,\n",
       " 'idea': 405,\n",
       " 'medicine': 406,\n",
       " 'now': 407,\n",
       " 'th': 408,\n",
       " 'times': 409,\n",
       " 'started': 410,\n",
       " 'keeping': 411,\n",
       " 'around': 412,\n",
       " 'However': 413,\n",
       " 'terrible': 414,\n",
       " 'difficult': 415,\n",
       " 'must': 416,\n",
       " 'leave': 417,\n",
       " 'power': 418,\n",
       " 'because': 419,\n",
       " 'sick': 420,\n",
       " 'love': 421,\n",
       " 'just': 422,\n",
       " 'received': 423,\n",
       " 'international': 424,\n",
       " 'call': 425,\n",
       " 'cellphone': 426,\n",
       " 'if': 427,\n",
       " 'Korea': 428,\n",
       " 'quarantine': 429,\n",
       " 'depot': 430,\n",
       " 'symptoms': 431,\n",
       " 'free': 432,\n",
       " 'lets': 433,\n",
       " 'hang': 434,\n",
       " 'tokyo': 435,\n",
       " 'haha': 436,\n",
       " 'xD': 437,\n",
       " 'im': 438,\n",
       " 'soo': 439,\n",
       " 'till': 440,\n",
       " 'next': 441,\n",
       " 'month': 442,\n",
       " 'caz': 443,\n",
       " 'don': 444,\n",
       " 'until': 445,\n",
       " 'nickname': 446,\n",
       " 'studied': 447,\n",
       " 'applied': 448,\n",
       " 'physics': 449,\n",
       " 'electronics': 450,\n",
       " 'Tokyo': 451,\n",
       " 'parents': 452,\n",
       " 'brother': 453,\n",
       " 'sister': 454,\n",
       " 'Fukuoka': 455,\n",
       " 'located': 456,\n",
       " 'northern': 457,\n",
       " 'part': 458,\n",
       " 'Kyushu': 459,\n",
       " 'Kyushe': 460,\n",
       " 'Archipelago': 461,\n",
       " 'Narita': 462,\n",
       " 'Airport': 463,\n",
       " 'far': 464,\n",
       " 'central': 465,\n",
       " 'Moreover': 466,\n",
       " 'crowded': 467,\n",
       " 'city': 468,\n",
       " 'lesson': 469,\n",
       " 'Halloween': 470,\n",
       " 'elementary': 471,\n",
       " 'teacher': 472,\n",
       " 'as': 473,\n",
       " 'might': 474,\n",
       " 'some': 475,\n",
       " 'actually': 476,\n",
       " 'topic': 477,\n",
       " 'trivias': 478,\n",
       " 'Bingo': 479,\n",
       " 'glad': 480,\n",
       " 'find': 481,\n",
       " 'believe': 482,\n",
       " 'lead': 483,\n",
       " 'accepting': 484,\n",
       " 'cloudy': 485,\n",
       " 'rainy': 486,\n",
       " 'recently': 487,\n",
       " 'washing': 488,\n",
       " 'ended': 489,\n",
       " 'evening': 490,\n",
       " 'shop': 491,\n",
       " 'inner': 492,\n",
       " 'decorating': 493,\n",
       " 'green': 494,\n",
       " 'They': 495,\n",
       " 'were': 496,\n",
       " 'easy': 497,\n",
       " 'cooking': 498,\n",
       " 'but': 499,\n",
       " 'tasted': 500,\n",
       " 'nice': 501,\n",
       " 'appreciate': 502,\n",
       " 'teach': 503,\n",
       " 'looking': 504,\n",
       " 'class': 505,\n",
       " 'here': 506,\n",
       " 'surprised': 507,\n",
       " 'progress': 508,\n",
       " 'owe': 509,\n",
       " 'remainder': 510,\n",
       " 'games': 511,\n",
       " 'Therefore': 512,\n",
       " 'position': 513,\n",
       " 'cheered': 514,\n",
       " 'miracle': 515,\n",
       " 'never': 516,\n",
       " 'happened': 517,\n",
       " 'jog': 518,\n",
       " 'exercise': 519,\n",
       " 'always': 520,\n",
       " 'wanna': 521,\n",
       " 'six': 522,\n",
       " 'pack': 523,\n",
       " 'weekend': 524,\n",
       " 'three': 525,\n",
       " 'holidays': 526,\n",
       " 'Saturday': 527,\n",
       " 'Sunday': 528,\n",
       " 'Monday': 529,\n",
       " 'close': 530,\n",
       " 'Equinox': 531,\n",
       " 'gradually': 532,\n",
       " 'waiting': 533,\n",
       " 'cherry': 534,\n",
       " 'blossoms': 535,\n",
       " 'Yesterday': 536,\n",
       " 'also': 537,\n",
       " 'Next': 538,\n",
       " 'week': 539,\n",
       " 'trips': 540,\n",
       " 'little': 541,\n",
       " 'starred': 542,\n",
       " 'play': 543,\n",
       " 'friendships': 544,\n",
       " 'National': 545,\n",
       " 'Children': 546,\n",
       " 'playing': 547,\n",
       " 'longtime': 548,\n",
       " 'realized': 549,\n",
       " 'could': 550,\n",
       " 'help': 551,\n",
       " 'people': 552,\n",
       " 'Reading': 553,\n",
       " 'happy': 554,\n",
       " 'told': 555,\n",
       " 'would': 556,\n",
       " 'speak': 557,\n",
       " 'boring': 558,\n",
       " 'remember': 559,\n",
       " 'which': 560,\n",
       " 'food': 561,\n",
       " 'available': 562,\n",
       " 'corner': 563,\n",
       " 'Thailand': 564,\n",
       " 'birds': 565,\n",
       " 'feather': 566,\n",
       " 'flock': 567,\n",
       " 'together': 568,\n",
       " 'walking': 569,\n",
       " 'posture': 570,\n",
       " 'small': 571,\n",
       " 'talkthere': 572,\n",
       " 'left': 573,\n",
       " 'shouted': 574,\n",
       " 'name': 575,\n",
       " 'stopped': 576,\n",
       " 'student': 577,\n",
       " 'Hi': 578,\n",
       " 'learn': 579,\n",
       " 'Whe': 580,\n",
       " 'become': 581,\n",
       " 'london': 582,\n",
       " 'since': 583,\n",
       " 'cant': 584,\n",
       " 'please': 585,\n",
       " 'graduate': 586,\n",
       " 'Culture': 587,\n",
       " 'shames': 588,\n",
       " 'common': 589,\n",
       " 'Every': 590,\n",
       " 'parent': 591,\n",
       " 'their': 592,\n",
       " 'children': 593,\n",
       " 'trouble': 594,\n",
       " 'others': 595,\n",
       " 'mistakes': 596,\n",
       " 'Thanks': 597,\n",
       " 'lol': 598,\n",
       " 'job': 599,\n",
       " 'seeked': 600,\n",
       " 'paper': 601,\n",
       " 'place': 602,\n",
       " 'luck': 603,\n",
       " 'movie': 604,\n",
       " 'Twilight': 605,\n",
       " 'disgusting': 606,\n",
       " 'Edward': 607,\n",
       " 'cared': 608,\n",
       " 'Bella': 609,\n",
       " 'strong': 610,\n",
       " 'girl': 611,\n",
       " 'national': 612,\n",
       " 'team': 613,\n",
       " 'played': 614,\n",
       " 'against': 615,\n",
       " 'Australia': 616,\n",
       " 'Asia': 617,\n",
       " 'Cup': 618,\n",
       " 'win': 619,\n",
       " 'singing': 620,\n",
       " 'songs': 621,\n",
       " 'sung': 622,\n",
       " 'brewed': 623,\n",
       " 'stress': 624,\n",
       " 'karaoke': 625,\n",
       " 'Seiko': 626,\n",
       " 'Matsuda': 627,\n",
       " 'relaxed': 628,\n",
       " 'Maybe': 629,\n",
       " 'guitar': 630,\n",
       " 'father': 631,\n",
       " 'ago': 632,\n",
       " 'maybe': 633,\n",
       " 'owner': 634,\n",
       " 'trees': 635,\n",
       " 'japan': 636,\n",
       " 'reason': 637,\n",
       " 'bloom': 638,\n",
       " 'falling': 639,\n",
       " 'early': 640,\n",
       " 'human': 641,\n",
       " 'drink': 642,\n",
       " 'seeing': 643,\n",
       " 'tired': 644,\n",
       " 'appetite': 645,\n",
       " 'Sleeping': 646,\n",
       " 'untill': 647,\n",
       " 'JINMAO': 648,\n",
       " 'OBSERVATORY': 649,\n",
       " 'building': 650,\n",
       " 'fourtunely': 651,\n",
       " 'That': 652,\n",
       " 'boy': 653,\n",
       " 'justice': 654,\n",
       " 'called': 655,\n",
       " 'hero': 656,\n",
       " 'tetuzin': 657,\n",
       " 'means': 658,\n",
       " 'iron': 659,\n",
       " 'man': 660,\n",
       " 'remote': 661,\n",
       " 'control': 662,\n",
       " 'tool': 663,\n",
       " 'taken': 664,\n",
       " 'evil': 665,\n",
       " 'person': 666,\n",
       " 'Where': 667,\n",
       " 'does': 668,\n",
       " 'stands': 669,\n",
       " 'hint': 670,\n",
       " 'snorkel': 671,\n",
       " 'Okinawa': 672,\n",
       " 'Prefectural': 673,\n",
       " 'Peace': 674,\n",
       " 'Memorial': 675,\n",
       " 'Museum': 676,\n",
       " 'shoud': 677,\n",
       " 'happen': 678,\n",
       " 'war': 679,\n",
       " 'chinese': 680,\n",
       " 'birthday': 681,\n",
       " 'Besides': 682,\n",
       " 'pursuing': 683,\n",
       " 'model': 684,\n",
       " 'career': 685,\n",
       " 'met': 686,\n",
       " 'club': 687,\n",
       " 'Foreigners': 688,\n",
       " 'baby': 689,\n",
       " 'adult': 690,\n",
       " 'childs': 691,\n",
       " 'meet': 692,\n",
       " 'our': 693,\n",
       " 'skill': 694,\n",
       " 'even': 695,\n",
       " 'He': 696,\n",
       " 'his': 697,\n",
       " 'theory': 698,\n",
       " 'show': 699,\n",
       " 'features': 700,\n",
       " 'Parents': 701,\n",
       " 'dating': 702,\n",
       " 'Guys': 703,\n",
       " 'date': 704,\n",
       " 'exude': 705,\n",
       " 'both': 706,\n",
       " 'parties': 707,\n",
       " 'warmth': 708,\n",
       " 'charisma': 709,\n",
       " 'Sounds': 710,\n",
       " 'lit': 711,\n",
       " 'bit': 712,\n",
       " 'tricky': 713,\n",
       " 'roles': 714,\n",
       " 'enrolled': 715,\n",
       " 'April': 716,\n",
       " 'valuable': 717,\n",
       " 'Going': 718,\n",
       " 'abroad': 719,\n",
       " 'dream': 720,\n",
       " 'cherich': 721,\n",
       " 'opportunity': 722,\n",
       " 'Once': 723,\n",
       " 'mind': 724,\n",
       " 'persevere': 725,\n",
       " 'smaller': 726,\n",
       " 'other': 727,\n",
       " 'did': 728,\n",
       " 'illuminated': 729,\n",
       " 'during': 730,\n",
       " 'wo': 731,\n",
       " 'cold': 732,\n",
       " 'Wish': 733,\n",
       " 'Happy': 734,\n",
       " 'In': 735,\n",
       " 'Paradise': 736,\n",
       " 'Stephen': 737,\n",
       " 'brave': 738,\n",
       " 'gone': 739,\n",
       " 'failed': 740,\n",
       " 'pass': 741,\n",
       " 'examination': 742,\n",
       " 'Your': 743,\n",
       " 'lovely': 744,\n",
       " 'face': 745,\n",
       " 'look': 746,\n",
       " 'ray': 747,\n",
       " 'paradise': 748,\n",
       " 'Apparently': 749,\n",
       " 'world': 750,\n",
       " 'lopsided': 751,\n",
       " 'For': 752,\n",
       " 'Java': 753,\n",
       " 'particularly': 754,\n",
       " 'difficulty': 755,\n",
       " 'Really': 756,\n",
       " 'though': 757,\n",
       " 'Sometime': 758,\n",
       " 'felt': 759,\n",
       " 'frustrated': 760,\n",
       " 'despairing': 761,\n",
       " 'Wednesday': 762,\n",
       " 'economics': 763,\n",
       " 'seminor': 764,\n",
       " 'softball': 765,\n",
       " 'match': 766,\n",
       " 'read': 767,\n",
       " 'literature': 768,\n",
       " 'wrote': 769,\n",
       " 'auditor': 770,\n",
       " 'construction': 771,\n",
       " 'company': 772,\n",
       " 'industry': 773,\n",
       " 'faces': 774,\n",
       " 'serious': 775,\n",
       " 'crisis': 776,\n",
       " 'ask': 777,\n",
       " 'fovorite': 778,\n",
       " 'respond': 779,\n",
       " 'hobby': 780,\n",
       " 'reading': 781,\n",
       " 'books': 782,\n",
       " 'magazins': 783,\n",
       " 'thanks': 784,\n",
       " 'fix': 785,\n",
       " 'wrong': 786,\n",
       " 'busy': 787,\n",
       " 'short': 788,\n",
       " 'break': 789,\n",
       " 'Oh': 790,\n",
       " 'wanderful': 791,\n",
       " 'college': 792,\n",
       " 'Additionally': 793,\n",
       " 'travel': 794,\n",
       " 'New': 795,\n",
       " 'York': 796,\n",
       " 'Disney': 797,\n",
       " 'Sea': 798,\n",
       " 'attraction': 799,\n",
       " 'excited': 800,\n",
       " 'spend': 801,\n",
       " 'weather': 802,\n",
       " 'Sommer': 803,\n",
       " 'eagerly': 804,\n",
       " 'come': 805,\n",
       " 'Steeven': 806,\n",
       " 'tought': 807,\n",
       " 'proud': 808,\n",
       " 'Shinkansen': 809,\n",
       " 'quiet': 810,\n",
       " 'forecast': 811,\n",
       " 'opened': 812,\n",
       " 'window': 813,\n",
       " 'rain': 814,\n",
       " 'fine': 815,\n",
       " 'There': 816,\n",
       " 'expect': 817,\n",
       " 'sports': 818,\n",
       " 'Buddhist': 819,\n",
       " 'memorial': 820,\n",
       " 'service': 821,\n",
       " 'return': 822,\n",
       " 'station': 823,\n",
       " 'near': 824,\n",
       " 'meeting': 825,\n",
       " 'street': 826,\n",
       " 'Last': 827,\n",
       " 'fee': 828,\n",
       " 'once': 829,\n",
       " 'umbrella': 830,\n",
       " 'woke': 831,\n",
       " 'move': 832,\n",
       " 'note': 833,\n",
       " 'something': 834,\n",
       " 'need': 835,\n",
       " 'great': 836,\n",
       " 'us': 837,\n",
       " 'enjoying': 838,\n",
       " 'commute': 839,\n",
       " 'Now': 840,\n",
       " 'greentea': 841,\n",
       " 'simply': 842,\n",
       " 'process': 843,\n",
       " 'After': 844,\n",
       " 'mede': 845,\n",
       " 'drunk': 846,\n",
       " 'What': 847,\n",
       " 'bitter': 848,\n",
       " 'Why': 849,\n",
       " 'taste': 850,\n",
       " 'send': 851,\n",
       " 'mail': 852,\n",
       " 'sooner': 853,\n",
       " 'earthquake': 854,\n",
       " 'bad': 855,\n",
       " 'family': 856,\n",
       " 'gran': 857,\n",
       " 'ma': 858,\n",
       " 'safe': 859,\n",
       " 'cousins': 860,\n",
       " 'Ca': 861,\n",
       " 'say': 862,\n",
       " 'fries': 863,\n",
       " 'potatoes': 864,\n",
       " 'Huang': 865,\n",
       " 'river': 866,\n",
       " 'second': 867,\n",
       " 'longest': 868,\n",
       " 'China': 869,\n",
       " 'crowling': 870,\n",
       " 'everywhere': 871,\n",
       " 'instinct': 872,\n",
       " 'tells': 873,\n",
       " 'gets': 874,\n",
       " 'silence': 875,\n",
       " 'dangerous': 876,\n",
       " 'sign': 877,\n",
       " 'growing': 878,\n",
       " 'step': 879,\n",
       " 'vacation': 880,\n",
       " 'coming': 881,\n",
       " 'shortly': 882,\n",
       " 'How': 883,\n",
       " 'fast': 884,\n",
       " 'goes': 885,\n",
       " 'slept': 886,\n",
       " 'late': 887,\n",
       " 'absolutely': 888,\n",
       " 'result': 889,\n",
       " 'rapid': 890,\n",
       " 'aging': 891,\n",
       " 'society': 892,\n",
       " 'fewer': 893,\n",
       " 'forward': 894,\n",
       " 'NY': 895,\n",
       " 'getting': 896,\n",
       " 'change': 897,\n",
       " 'fulfillment': 898,\n",
       " 'Seoul': 899,\n",
       " 'use': 900,\n",
       " 'line': 901,\n",
       " 'stores': 902,\n",
       " 'method': 903,\n",
       " 'charging': 904,\n",
       " 'simple': 905,\n",
       " 'credit': 906,\n",
       " 'card': 907,\n",
       " 'numbers': 908,\n",
       " 'worried': 909,\n",
       " 'whether': 910,\n",
       " 'catch': 911,\n",
       " 'Finally': 912,\n",
       " 'choose': 913,\n",
       " 'official': 914,\n",
       " 'web': 915,\n",
       " 'site': 916,\n",
       " 'prices': 917,\n",
       " 'expensive': 918,\n",
       " 'arriving': 919,\n",
       " 'soon': 920,\n",
       " 'fisrt': 921,\n",
       " 'typhoon': 922,\n",
       " 'More': 923,\n",
       " 'consideration': 924,\n",
       " 'feelings': 925,\n",
       " 'matter': 926,\n",
       " 'realize': 927,\n",
       " 'important': 928,\n",
       " 'cry': 929,\n",
       " 'after': 930,\n",
       " 'bed': 931,\n",
       " 'Hello': 932,\n",
       " 'sorry': 933,\n",
       " 'dialy': 934,\n",
       " 'sleeped': 935,\n",
       " 'hours': 936,\n",
       " 'sleeping': 937,\n",
       " 'Thank': 938,\n",
       " 'visited': 939,\n",
       " 'Freemarket': 940,\n",
       " 'held': 941,\n",
       " 'park': 942,\n",
       " 'sounds': 943,\n",
       " 'steps': 944,\n",
       " 'Yes': 945,\n",
       " 'boss': 946,\n",
       " 'ear': 947,\n",
       " 'survival': 948,\n",
       " 'Even': 949,\n",
       " 'counld': 950,\n",
       " 'm': 951,\n",
       " 'JST': 952,\n",
       " 'Standard': 953,\n",
       " 'Time': 954,\n",
       " 'univercity': 955,\n",
       " 'test': 956,\n",
       " 'wantet': 957,\n",
       " 'weak': 958,\n",
       " 'understanding': 959,\n",
       " 'accents': 960,\n",
       " 'yoshimi': 961,\n",
       " 'introduced': 962,\n",
       " 'website': 963,\n",
       " 'ca': 964,\n",
       " 'words': 965,\n",
       " 'dreamed': 966,\n",
       " 'before': 967,\n",
       " 'drank': 968,\n",
       " 'beer': 969,\n",
       " 'asked': 970,\n",
       " 'boyfriend': 971,\n",
       " 'answered': 972,\n",
       " 'disappointed': 973,\n",
       " 'Someday': 974,\n",
       " 'Come': 975,\n",
       " 'chance': 976,\n",
       " 'surely': 977,\n",
       " 'Only': 978,\n",
       " 'problem': 979,\n",
       " 'heavy': 980,\n",
       " 'wanted': 981,\n",
       " 'wonderful': 982,\n",
       " 'architectures': 983,\n",
       " 'foreign': 984,\n",
       " 'earlier': 985,\n",
       " 'thought': 986,\n",
       " 'young': 987,\n",
       " 'already': 988,\n",
       " 'buzy': 989,\n",
       " 'faster': 990,\n",
       " 'usual': 991,\n",
       " 'elder': 992,\n",
       " 'fag': 993,\n",
       " 'overtime': 994,\n",
       " 'Asashoryu': 995,\n",
       " 'Sumo': 996,\n",
       " 'champion': 997,\n",
       " 'traditional': 998,\n",
       " 'accused': 999,\n",
       " 'puching': 1000,\n",
       " 'while': 1001,\n",
       " ...}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lang.word2index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seq2Seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n",
    "\n",
    "    def forward_step(self, input, hidden):\n",
    "        output = self.embedding(input)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Va = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, keys)\n",
    "\n",
    "        return context, weights\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions\n",
    "\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        embedded =  self.dropout(self.embedding(input))\n",
    "\n",
    "        query = hidden.permute(1, 0, 2)\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        input_gru = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        output, hidden = self.gru(input_gru, hidden)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Data for Seq2Seq Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 496255 sentence pairs\n",
      "Trimmed to 266109 sentence pairs\n",
      "Counting words...\n",
      "length of first 50000 pairs 50000\n",
      "Counted words:\n",
      "eng 60326\n",
      "eng 49505\n"
     ]
    }
   ],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "def get_dataloader(batch_size):\n",
    "    input_lang, output_lang, pairs = prepareData('eng', 'eng', True)\n",
    "\n",
    "    n = len(pairs)\n",
    "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "\n",
    "    for idx, (inp, tgt) in enumerate(pairs):\n",
    "        inp_ids = indexesFromSentence(input_lang, inp)\n",
    "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
    "        inp_ids.append(EOS_token)\n",
    "        tgt_ids.append(EOS_token)\n",
    "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "\n",
    "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
    "                               torch.LongTensor(target_ids).to(device))\n",
    "\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "    return input_lang, output_lang, train_dataloader\n",
    "\n",
    "batch_size = 32\n",
    "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1563"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion):\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
    "               print_every=100, plot_every=100):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
    "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            decoded_words.append(output_lang.index2word[idx.item()])\n",
    "    return decoded_words, decoder_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    bleu_scores = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        reference = [pair[1].split(' ')]\n",
    "        candidate = output_sentence.split(' ')\n",
    "        score = sentence_bleu(reference, candidate)\n",
    "        print(\"BLEU score\", score)\n",
    "        bleu_scores.append(score)\n",
    "        print('')\n",
    "\n",
    "    print(\"Average BLEU score:\", sum(bleu_scores) / len(bleu_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32m 29s (- 487m 19s) (5 6%) 2.1439\n",
      "56m 22s (- 394m 40s) (10 12%) 1.0295\n",
      "93m 32s (- 405m 19s) (15 18%) 0.7254\n",
      "117m 24s (- 352m 12s) (20 25%) 0.5863\n",
      "140m 32s (- 309m 12s) (25 31%) 0.5014\n",
      "163m 51s (- 273m 5s) (30 37%) 0.4419\n",
      "187m 14s (- 240m 44s) (35 43%) 0.3978\n",
      "211m 9s (- 211m 9s) (40 50%) 0.3629\n",
      "233m 54s (- 181m 55s) (45 56%) 0.3344\n",
      "258m 0s (- 154m 48s) (50 62%) 0.3114\n",
      "282m 32s (- 128m 25s) (55 68%) 0.2910\n",
      "307m 3s (- 102m 21s) (60 75%) 0.2742\n",
      "330m 58s (- 76m 22s) (65 81%) 0.2593\n",
      "354m 25s (- 50m 37s) (70 87%) 0.2463\n",
      "377m 54s (- 25m 11s) (75 93%) 0.2348\n",
      "401m 37s (- 0m 0s) (80 100%) 0.2244\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 128\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "train(train_dataloader, encoder, decoder, 80, print_every=5, plot_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Do your best I am so next week\n",
      "= I am going to do my best next week\n",
      "< I will do the best this I am so next week <EOS>\n",
      "BLEU score 8.190757052088229e-155\n",
      "\n",
      "> It looks like more deep pink than Japanese one\n",
      "= They are more deep pink than the Japanese ones\n",
      "< They are more deep pink than the Japanese ones <EOS>\n",
      "BLEU score 0.8801117367933934\n",
      "\n",
      "> Anyway I jogged km it was not bad\n",
      "= Anyway I jogged km It was not bad\n",
      "< Anyway I jogged km It was not bad <EOS>\n",
      "BLEU score 0.8633400213704505\n",
      "\n",
      "> Please crrect my Poor English sentences\n",
      "= Please correct my poor English sentences\n",
      "< Please correct my poor English sentences <EOS>\n",
      "BLEU score 0.8091067115702212\n",
      "\n",
      "> because I had to sales analysis today\n",
      "= because I had to do a sales analysis today\n",
      "< because I had to do a sales analysis today <EOS>\n",
      "BLEU score 0.8801117367933934\n",
      "\n",
      "> SPI make me crazy\n",
      "= SPI makes me crazy\n",
      "< SPI makes me crazy <EOS>\n",
      "BLEU score 0.668740304976422\n",
      "\n",
      "> Californication Times like these\n",
      "= Californication Times Like These\n",
      "< Californication Times Like These <EOS>\n",
      "BLEU score 0.668740304976422\n",
      "\n",
      "> I am still keep in bed now\n",
      "= I am still in bed now\n",
      "< I am still in bed now <EOS>\n",
      "BLEU score 0.8091067115702212\n",
      "\n",
      "> I felt relief\n",
      "= I felt relieved\n",
      "< I felt relieved behavior relief <EOS>\n",
      "BLEU score 5.775353993361614e-78\n",
      "\n",
      "> I am afraid to fall asleep during the meeting\n",
      "= I am afraid I will fall asleep during the meeting\n",
      "< I am afraid I will fall asleep during the meeting <EOS>\n",
      "BLEU score 0.8931539818068694\n",
      "\n",
      "Average BLEU score: 0.6472411509857394\n"
     ]
    }
   ],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = I heard it was the popular book in America\n",
      "output = I heard it was a popular book in America <EOS>\n"
     ]
    }
   ],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.cpu().numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(encoder, decoder, input_sentence, input_lang, output_lang)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions[0, :len(output_words), :])\n",
    "\n",
    "evaluateAndShowAttention('I heard it was the popular book in America')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOSeiMfGWPHsZWAsPszc3/u",
   "collapsed_sections": [],
   "mount_file_id": "12cEbNqoYSRnEG775wFUBUeYi6sWQPmCU",
   "name": "CS02.01 Data Extraction",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
